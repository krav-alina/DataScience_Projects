{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Данные-загружены-и-подготовлены.-Разделены-на-три-выборки\" data-toc-modified-id=\"Данные-загружены-и-подготовлены.-Разделены-на-три-выборки-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><font color=\"orange\">Данные загружены и подготовлены. Разделены на три выборки</font></a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#-Для-получения-необходимого-результата-я-сначала-пытаюсь-обучить-логистическую-регрессию-с-различными-параметрами-токенизатора.-Лучший-результат-на-этой-модели-показал-TFiDf-со-стоп-словами-и-твит-токенизатором.-В-качестве-пфичей-подавались-униграммы-и-биграммы.\" data-toc-modified-id=\"-Для-получения-необходимого-результата-я-сначала-пытаюсь-обучить-логистическую-регрессию-с-различными-параметрами-токенизатора.-Лучший-результат-на-этой-модели-показал-TFiDf-со-стоп-словами-и-твит-токенизатором.-В-качестве-пфичей-подавались-униграммы-и-биграммы.-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><font color=\"orange\"> Для получения необходимого результата я сначала пытаюсь обучить логистическую регрессию с различными параметрами токенизатора. Лучший результат на этой модели показал TFiDf со стоп-словами и твит токенизатором. В качестве пфичей подавались униграммы и биграммы.</font></a></span></li><li><span><a href=\"#Вот-лучший-результат-регрессии.\" data-toc-modified-id=\"Вот-лучший-результат-регрессии.-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><font color=\"orange\">Вот лучший результат регрессии.</font></a></span></li><li><span><a href=\"#-Попытаемся-получить-результаты-лучше-на-случайном-лесе.\" data-toc-modified-id=\"-Попытаемся-получить-результаты-лучше-на-случайном-лесе.-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span><font color=\"orange\"> Попытаемся получить результаты лучше на случайном лесе.</font></a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span><ul class=\"toc-item\"><li><span><a href=\"#-Не-смогла-добиться-необходимой-метрики.-Пыталась-обучать-модели-с-разными-гиперпараметрами.-Специально-не-убирала-пунктуацию,-потому-что-предполагала,-что-в-твитах-пунктуация-может-служить-дополнительным-показателем-эмоций-(напр,-:),-:()\" data-toc-modified-id=\"-Не-смогла-добиться-необходимой-метрики.-Пыталась-обучать-модели-с-разными-гиперпараметрами.-Специально-не-убирала-пунктуацию,-потому-что-предполагала,-что-в-твитах-пунктуация-может-служить-дополнительным-показателем-эмоций-(напр,-:),-:()-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><font color=\"orange\"> Не смогла добиться необходимой метрики. Пыталась обучать модели с разными гиперпараметрами. Специально не убирала пунктуацию, потому что предполагала, что в твитах пунктуация может служить дополнительным показателем эмоций (напр, :), :()</font></a></span></li></ul></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ],
   "metadata": {
    "toc": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Проект для «Викишоп»"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import nltk\r\n",
    "#nltk.download('wordnet')\r\n",
    "from nltk.stem import WordNetLemmatizer \r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from nltk.corpus import stopwords\r\n",
    "import sklearn.linear_model as lm\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from nltk import ngrams\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import lightgbm as lgb\r\n",
    "from nltk.tokenize import TweetTokenizer\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.model_selection import RandomizedSearchCV\r\n",
    "from scipy.stats import randint\r\n",
    "from nltk.tokenize import word_tokenize\r\n",
    "import re\r\n",
    "from string import punctuation"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "tknzr = TweetTokenizer()\r\n",
    "wordNet = WordNetLemmatizer()\r\n",
    "stopwords = set(stopwords.words('english'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Спасибо, что не забываешь собирать все импорты в верхней части ноутбука.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159566</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159567</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159568</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159569</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159570</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены верно.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Но не забывай про проверку на пропуски (метод info).\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#corpus = data['text'].values.astype('U')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def my_preproc(text):\n",
    "    text = wordNet.lemmatize(text) \n",
    "    return [word for word in text if word not in stopwords.words('english') + [' ', '\\n']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def my_preproc_tweet(text):\n",
    "    text = wordNet.lemmatize(text) \n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    return [word for word in text if word not in stopwords.words('english') + [' ', '\\n']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Лемматизация определена верно.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Однако, я бы предварительно очистил текст от небуквенных символом. Также, можно было напечатать несколько примеров до/после.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> В целом, можно просто лемматизировать весь текст, а не переносить лемматизацию в векторизатор. Если ты сделаешь ее всего 1 раз, то это будет значительно быстрее, чем если при каждой векторизации.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features_train, features_valid, target_train, target_valid = train_test_split(data.text, data.toxic, test_size = 0.4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size = 0.25)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Разбиение было сделано верно. Однако, замечу, что ты разделила в соотношении: 6:3:1.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color='orange'>Данные загружены и подготовлены. Разделены на три выборки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обучение"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color='orange'> Для получения необходимого результата я сначала пытаюсь обучить логистическую регрессию с различными параметрами токенизатора. Лучший результат на этой модели показал TFiDf со стоп-словами и твит токенизатором. В качестве пфичей подавались униграммы и биграммы."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(features_train)\n",
    "clf = LogisticRegression(class_weight='balanced')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "clf.fit(bow, target_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.32733353870527654\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(features_train)\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(bow, target_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3304639562088907\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=word_tokenize, stop_words=stopwords)\n",
    "bow = vec.fit_transform(features_train)\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "clf.fit(bow, target_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "c:\\users\\sidor\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7357587794529206\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color='orange'>Вот лучший результат регрессии."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tknzr.tokenize, stop_words=stopwords)\n",
    "bow = vec.fit_transform(features_train)\n",
    "clf = LogisticRegression(C= 0.4) # class_weight='balanced'\n",
    "clf.fit(bow, target_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7394608286593088\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Все сделано правильно, молодец! Радует, что ты написала свой токенизатор и попробовала готовый.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Проще всего достичь требуемого качества путем подбора параметра C к логистической регрессии. В данном случае ты можешь это сделать на валидационной выборке. Если же ты будешь использовать метод основанный на кросс-валидации, то валидационную выборку можно не выделять, так как она нам не нужна.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> параметр С почему-то у меня так и не сработал, выдавал ошибку TypeError: __init__() got an unexpected keyword argument 'С'. Что-то из инте я так и не поняла,с чем она свзана. Пробоавла так: clf = LogisticRegression(С=1.0)\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет (ревью 2): </b> Возможно ты использовала русскую букву \"С\", а не английскую \"C\"?\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color='orange'> Попытаемся получить результаты лучше на случайном лесе."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tknzr.tokenize, stop_words=stopwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "bow = vec.fit_transform(features_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "model_params = {\n",
    "     'n_estimators': randint(8,9), \n",
    "     'max_depth': randint(3000,3001)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "rf_model = RandomForestClassifier()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "clf = RandomizedSearchCV(rf_model, model_params, n_iter=20, scoring='f1', cv=3, random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "clf.fit(bow, target_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=20, n_jobs=None,\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000012EE188CE08>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000012EAFCF7808>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.566988055835372\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "pred = clf.predict(vec.transform(features_test))\n",
    "print(f1_score(target_test,pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5779896013864818\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Случайный лес не очень хорошо работает с данными такого типа.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Переделала с помощью lgb классификатора и оставленной пунктуации получилась самая успешная модель. Нужный результат достигнут! \n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tknzr.tokenize, stop_words=stopwords)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "bow = vec.fit_transform(features_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(bow, target_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "pred = clf.predict(vec.transform(features_valid))\n",
    "print(f1_score(pred, target_valid))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7518672199170123\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "pred = clf.predict(vec.transform(features_test))\n",
    "print(f1_score(target_test,pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7510980966325036\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Также я пыталась обучать lgb с убранной пунктуацией, но обучалась модель очень долго у меня в тетрадке на компе, и результат на валидационной выборке получился - 0.4930259873733666. Поэтому я здесь обучать не буду\n",
    "</div> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 2), tokenizer=my_preproc_tweet)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Тут лучше использовать <a href=\"https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\">LGBMClassifier</a>.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех (ревью 2):</b> Отлично, молодец!\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Выводы"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### <font color='orange'> Не смогла добиться необходимой метрики. Пыталась обучать модели с разными гиперпараметрами. Специально не убирала пунктуацию, потому что предполагала, что в твитах пунктуация может служить дополнительным показателем эмоций (напр, :), :()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Это можно просто проверить, удали пунктуацию и сравни качество.\n",
    "</div>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Чек-лист проверки"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}